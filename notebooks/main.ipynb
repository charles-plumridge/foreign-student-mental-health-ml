{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019e4728",
   "metadata": {},
   "source": [
    "# Foreign Student Mental Health ML\n",
    "\n",
    "This project uses machine learning techniques to learn about influences on mental health of international and domestic students at Ritsumeikan Asia Pacific University in Japan and aims to build a model to predict students at risk of mental health issues such as depression and suicidal ideation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9ee481",
   "metadata": {},
   "source": [
    "### 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef29b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    ")\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "# Other\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# File paths\n",
    "DATA_PATH = Path(\"../data/data.csv\")\n",
    "CODEBOOK_PATH = Path(\"../data/feature_target_explanations.xlsx\")\n",
    "\n",
    "# Toggles\n",
    "INCLUDE_FSCORE2 = False  # set True to include feature-score == 2 variables\n",
    "# FLAGGING FOR LATER: Consider removing\n",
    "SHAP_SAMPLE_N = 300  # sample size for SHAP\n",
    "SHAP_TOP_K = 5  # how many top features to explain with SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1470554d",
   "metadata": {},
   "source": [
    "NOTE - add the following to preprocess the column names in the data csv, and the corresponding names in the codebook also (in the first column).\n",
    "\n",
    "df.columns = (df.columns.str.strip().str.lower().str.replace(\" \", \"_\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afccc8d3",
   "metadata": {},
   "source": [
    "### 2. Quick file existence check and preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b0da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data exists:\", DATA_PATH.exists())\n",
    "print(\"Codebook exists:\", CODEBOOK_PATH.exists())\n",
    "\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "print(\"Data shape:\", df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca5605",
   "metadata": {},
   "source": [
    "### 3. Load codebook and inspect - is this necessary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ed4890",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_numeric = pd.read_excel(CODEBOOK_PATH, sheet_name=\"numeric_variables\")\n",
    "cb_categorical = pd.read_excel(CODEBOOK_PATH, sheet_name=\"cat_variables\")\n",
    "display(cb_numeric.head())\n",
    "display(cb_categorical.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da463fab",
   "metadata": {},
   "source": [
    "### 4. Clean column and variable names *\n",
    "Need to confirm datatypes are correct and 0s are dealt with correctly. See plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e231fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(s: pd.Index | pd.Series) -> pd.Index | pd.Series:\n",
    "    \"\"\"Cleans by stripping whitespace, converting to lowercase,\n",
    "    and replacing spaces with underscores.\"\"\"\n",
    "    return s.str.strip().str.lower().str.replace(\" \", \"_\", regex=False)\n",
    "\n",
    "\n",
    "# Clean columns in data\n",
    "data.columns = clean_up(data.columns)\n",
    "\n",
    "# Clean columns in codebook\n",
    "cb_numeric.columns = clean_up(cb_numeric.columns)\n",
    "cb_categorical.columns = clean_up(cb_categorical.columns)\n",
    "\n",
    "# Clean variables in codebook\n",
    "cb_numeric[\"coded_name\"] = clean_up(cb_numeric[\"coded_name\"])\n",
    "cb_categorical[\"coded_name\"] = clean_up(cb_categorical[\"coded_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10948618",
   "metadata": {},
   "source": [
    "### 5. Aggregate codebook variables for analysis\n",
    "Only keeps categorical variables that do not have a numeric equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_numeric_vars = cb_numeric[[\"coded_name\", \"feature_score\", \"target_score\", \"filter_score\"]]\n",
    "potential_cat_vars = cb_categorical.loc[\n",
    "    cb_categorical[\"numeric_version_exists\"] == \"N\",\n",
    "    [\"coded_name\", \"feature_score\", \"target_score\", \"filter_score\"],\n",
    "]\n",
    "potential_vars_df = pd.concat([potential_numeric_vars, potential_cat_vars], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d1304",
   "metadata": {},
   "source": [
    "### Define targets (does this need its own cell?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1082fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = {\"depression\": \"ToDep\", \"ideation\": \"Suicide\", \"acculturative_stress\": \"ToAS\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb766f7a",
   "metadata": {},
   "source": [
    "### 5. Build feature list based on \"Feature Score\" attribute *\n",
    "\n",
    "The survey data variables were given scores for their suitability for being a feature, target, or for filtering the data (to examine certain populations).\n",
    "\n",
    "Based on the feature scores, the features are selected in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a878b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build feature list per rules:\n",
    "# include variables with feature_score==3, optionally include score==2 when toggle set\n",
    "fs3 = set(potential_vars_df.loc[potential_vars_df[\"feature_score\"] == 3, \"coded_name\"].tolist())\n",
    "fs2 = set(potential_vars_df.loc[potential_vars_df[\"feature_score\"] == 2, \"coded_name\"].tolist())\n",
    "if INCLUDE_FSCORE2:\n",
    "    features = fs3.union(fs2)\n",
    "else:\n",
    "    features = fs3.copy()\n",
    "\n",
    "# remove any target columns\n",
    "for col in TARGETS.values():\n",
    "    features.discard(col)\n",
    "\n",
    "# Ensure features and targets exist in data\n",
    "assert all(feat in data.columns for feat in features), \"Some candidate features not in data columns\"\n",
    "\n",
    "assert all(\n",
    "    targ in data.columns for targ in TARGETS.values()\n",
    "), \"Some target variables not in data columns\"\n",
    "\n",
    "# Print features and how many\n",
    "print(\"Number of features selected:\", len(features))\n",
    "print(\"Features selected:\", features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98b581",
   "metadata": {},
   "source": [
    "### split numeric vs categorical features (for ColumnTransformer)\n",
    "[is this necessary?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8df5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [c for c in features if c in cb_numeric[\"coded_name\"]]\n",
    "cat_features = [c for c in features if c not in numeric_features]\n",
    "print(\"Numeric features:\", len(numeric_features))\n",
    "print(\"Categorical features:\", len(cat_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c027fbc",
   "metadata": {},
   "source": [
    "### EDA heatmap\n",
    "Basic missingness and distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a4812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of missing data\n",
    "missing_summary = data[features + list(TARGETS.values())].isna().mean().sort_values(ascending=False)\n",
    "display(missing_summary)\n",
    "\n",
    "# Correlation heatmap for numeric features\n",
    "corr = data[numeric_features + list(TARGETS.values())].corr().round(3)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr, cmap=\"vlag\", center=0, annot=False)\n",
    "plt.title(\"Numeric features correlation matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb4aaf5",
   "metadata": {},
   "source": [
    "### Construct preprocessing pipelines (numeric + categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a585260",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")), (\"sc\", StandardScaler())])\n",
    "\n",
    "cat_pipe = Pipeline(\n",
    "    [\n",
    "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [(\"num\", num_pipe, numeric_features), (\"cat\", cat_pipe, cat_features)], remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a18bb49",
   "metadata": {},
   "source": [
    "### Helper - get feature names after ColumnTransformer (for importance mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49adc9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names_from_preprocessor(preprocessor):\n",
    "    \"\"\"Return list of feature names in the same order as transformed array columns\"\"\"\n",
    "    feature_names = []\n",
    "    for name, trans, cols in preprocessor.transformers_:\n",
    "        if name == \"remainder\":\n",
    "            continue\n",
    "        if hasattr(trans, \"named_steps\"):\n",
    "            # pipeline\n",
    "            last = list(trans.named_steps.values())[-1]\n",
    "\n",
    "            if hasattr(last, \"get_feature_names_out\"):\n",
    "                fn = last.get_feature_names_out(cols)\n",
    "                feature_names.extend(list(fn))\n",
    "            else:\n",
    "                feature_names.extend(list(cols))\n",
    "        else:\n",
    "            feature_names.extend(list(cols))\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55370257",
   "metadata": {},
   "source": [
    "### VIF function (run after fitting preprocessor)\n",
    "Variance Inflation Factor (VIF) quantifies how much a regression coefficientâ€™s variance is inflated due to multicollinearity. It is computed as $ 1/(1 - R^2) $, where $ R^2 $ comes from regressing one feature on all others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9a3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vif(preprocessor, X_df):\n",
    "    \"\"\"Transform and compute VIF on full preprocessed numeric matrix\"\"\"\n",
    "    X_prep = preprocessor.fit_transform(X_df)\n",
    "    X_arr = X_prep if isinstance(X_prep, np.ndarray) else X_prep.toarray()\n",
    "    names = get_feature_names_from_preprocessor(preprocessor)\n",
    "    vif_df = pd.DataFrame(\n",
    "        {\n",
    "            \"feature\": names,\n",
    "            \"VIF\": [variance_inflation_factor(X_arr, i) for i in range(X_arr.shape[1])],\n",
    "        }\n",
    "    ).sort_values(\"VIF\", ascending=False)\n",
    "    return vif_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b98cf",
   "metadata": {},
   "source": [
    "### Modeling utilities - Cross-validation evaluation for regression and classification\n",
    "OK up to and including this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3400f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regression(pipe, X, y, cv=5):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)\n",
    "    r2 = cross_val_score(pipe, X, y, cv=kf, scoring=\"r2\", n_jobs=-1)\n",
    "    rmse = -cross_val_score(pipe, X, y, cv=kf, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "    mae = -cross_val_score(pipe, X, y, cv=kf, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "    return {\n",
    "        \"r2_mean\": r2.mean(),\n",
    "        \"r2_std\": r2.std(),\n",
    "        \"rmse_mean\": rmse.mean(),\n",
    "        \"rmse_std\": rmse.std(),\n",
    "        \"mae_mean\": mae.mean(),\n",
    "        \"mae_std\": mae.std(),\n",
    "    }\n",
    "\n",
    "\n",
    "# MUST GO THROUGH THE BELOW STEP BY STEP.\n",
    "def eval_classification(pipe, X, y, cv=5):\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)\n",
    "    roc = cross_val_score(pipe, X, y, cv=skf, scoring=\"roc_auc\", n_jobs=-1)\n",
    "    # PR-AUC approximate via precision_recall_curve on cross_val_predict\n",
    "    prob = cross_val_predict(pipe, X, y, cv=skf, method=\"predict_proba\", n_jobs=-1)\n",
    "    # prob[:,1] exists when pipeline returns classifier with predict_proba\n",
    "    # compute per-fold PR-AUC manually is expensive; approximate with full P-R curve\n",
    "    pr, re, _ = precision_recall_curve(y, prob[:, 1])\n",
    "    pr_auc_full = auc(re, pr)\n",
    "    return {\"roc_auc_mean\": roc.mean(), \"roc_auc_std\": roc.std(), \"pr_auc\": pr_auc_full}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378799d2",
   "metadata": {},
   "source": [
    "### Define models to run (regression and classification sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be38e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = {\n",
    "    \"OLS\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(random_state=RANDOM_STATE),\n",
    "    \"Lasso\": Lasso(random_state=RANDOM_STATE),\n",
    "    \"ElasticNet\": ElasticNet(random_state=RANDOM_STATE),\n",
    "    \"RF\": RandomForestRegressor(n_estimators=200, random_state=RANDOM_STATE),\n",
    "    \"XGB\": xgb.XGBRegressor(random_state=RANDOM_STATE, verbosity=0),\n",
    "}\n",
    "\n",
    "classifiers = {\n",
    "    \"Logistic\": LogisticRegression(max_iter=2000, random_state=RANDOM_STATE),\n",
    "    \"Logistic_EN\": LogisticRegression(\n",
    "        penalty=\"elasticnet\", solver=\"saga\", l1_ratio=0.5, max_iter=2000, random_state=RANDOM_STATE\n",
    "    ),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE),\n",
    "    \"XGB\": xgb.XGBClassifier(random_state=RANDOM_STATE, use_label_encoder=False, verbosity=0),\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".student-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
